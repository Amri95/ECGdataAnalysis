{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.python import load_database,ECG_denoising\n",
    "from codes.python import QRS_detector\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.signal import savgol_filter\n",
    "import operator\n",
    "from numpy import array\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "from wfdb import processing, plot\n",
    "from codes.python import heartbeat_segmentation as shs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from biosppy.signals import ecg\n",
    "from sklearn import metrics\n",
    "#import waipy\n",
    "import operator\n",
    "from codes.python import ecg_waveform_extractor as waveform\n",
    "import time as system_time\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import termcolor as colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(numbers):\n",
    "    return float(sum(numbers)) / len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mitdb = load_database.load_mitdb()\n",
    "mitdb.segment_beats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit100 = load_database.load_patient_record(\"mitdb\",\"100\")\n",
    "mit100.set_segmented_beats_r_pos(winL=100,winR=200)\n",
    "filtere_MLII = mit100.filtered_MLII\n",
    "beats, poses = shs.segment(filtere_MLII,100,50,50,25)\n",
    "assert len(beats) == 100\n",
    "assert max(filtere_MLII[beats]) == filtere_MLII[poses],\"max(pos) isn't equal to r_pos \"\n",
    "count = 0\n",
    "assert shs.check_class_AAMI('N',-1) == 0\n",
    "\n",
    "for patient in mitdb.patient_records:\n",
    "    patient.set_Q_S_points_MLII()\n",
    "\n",
    "\n",
    "\n",
    "    #r_peak_properties\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for patient in mitdb.patient_records:\n",
    "    \n",
    "    \n",
    "    print(patient.filename, count)\n",
    "    count += 1\n",
    "    assert len(patient.original_R_pos) == len(patient.segmented_R_pos) == len(patient.segmented_beat_time) == len(patient.segmented_beat_index),\"Unequal length, should be equal in length\"\n",
    "    assert len(patient.segmented_beat_1) == len(patient.segmented_class_ID) == len(patient.segmented_beat_class),\"Unequal lens, should be equal in length\"\n",
    "    \n",
    "    \n",
    "    assert len(patient.Q_points) == len(patient.S_points),\"Unequal lens, should be equal in length\"\n",
    "    assert len(patient.segmented_R_pos) == len(patient.S_points),\"Unequal lens, should be equal in length\"\n",
    "    r_properties = waveform.r_peak_properties_extractor(patient,to_area=False)\n",
    "    assert len(r_properties[\"height\"]) == len(patient.segmented_R_pos),\"Unequal lens, should be equal in length\"\n",
    "    assert average(r_properties[\"height\"]) < 3,\"Average height of r_peak for patient \"+ patient.filename+ \" is greater than 3\"\n",
    "    assert average(r_properties[\"height\"]) > 0.5,\"Average height of r_peak for patient \" +patient.filename+ \" is less than 0.5\"\n",
    "    assert min(r_properties[\"height\"]) >= 0,\"Min height of r_peak for patient \" +patient.filename+ \" is less than 0\"\n",
    "    assert max(r_properties[\"height\"]) < 5,\"Max height of r_peak for patient \" +patient.filename+ \" is greater than 5\"\n",
    "    x ,y  = np.unique(r_properties[\"height\"], return_counts=True) # counting occurrence of each loan\n",
    "    index = np.where(x==0)\n",
    "    index = np.asarray(index)\n",
    "    if(index.size != 0):\n",
    "        \n",
    "        if(y[index[0]] > 20):\n",
    "            warnings.warn(\"height equal to 0 number is greater then 20 in \" + patient.filename + \" record with 0 height number of \"+ str(y[index[0]]))\n",
    "        \n",
    "    \n",
    "    assert len(r_properties[\"durations\"]) == len(patient.segmented_R_pos),\"Unequal lens, should be equal in length\"\n",
    "    assert average(r_properties[\"durations\"]) < 0.09,\"Average duration of r_peak for patient \"+ patient.filename+ \" is greater than 0.09\"\n",
    "    assert average(r_properties[\"durations\"]) > 0.01,\"Average durations of r_peak for patient \" +patient.filename+ \" is less than 0.01\"\n",
    "    assert min(r_properties[\"durations\"]) >= 0,\"Min durations of r_peak for patient \" +patient.filename+ \" is less than 0\"\n",
    "    assert max(r_properties[\"durations\"]) < 0.3,\"Max durations of r_peak for patient \" +patient.filename+ \" is greater than 0.3\"\n",
    "    x ,y  = np.unique(r_properties[\"durations\"], return_counts=True) # counting occurrence of each loan\n",
    "    index = np.where(x==0)\n",
    "    index = np.asarray(index)\n",
    "    if(index.size != 0):\n",
    "        \n",
    "        if(y[index[0]] > 20):\n",
    "            warnings.warn(\"durations equal to 0 number is greater then 20 in \" + patient.filename + \" record with 0 durations number of \"+ str(y[index[0]]))\n",
    "        \n",
    "    \n",
    "    assert len(r_properties[\"onset\"]) == len(patient.segmented_R_pos),\"Unequal lens, should be equal in length\"   \n",
    "    assert len(r_properties[\"offset\"]) == len(patient.segmented_R_pos),\"Unequal lens, should be equal in length\" \n",
    "    \n",
    "    #print(r_properties[\"offset\"])\n",
    "\n",
    "    for i in range(0,len(patient.segmented_R_pos)-1):\n",
    "        assert len(patient.segmented_beat_1[i])==len(patient.segmented_beat_1[i+1]), \"Unequal lens, should be equal in length\"\n",
    "        assert len(patient.segmented_beat_time[i]) == len(patient.segmented_beat_time[i+1]), \"Unequal lens, should be equal in length\"\n",
    "        assert len(patient.segmented_beat_1[i])==len(patient.segmented_beat_time[i]), \"Unequal lens, should be equal in length\"\n",
    "        assert patient.segmented_R_pos[i] <= patient.segmented_R_pos[i+1], \"the later r_pos is smaller \" + patient.filename + \" R_peak: \" + str(patient.segmented_R_pos[i]) +\" \"+  str(patient.segmented_R_pos[i+1])\n",
    "        assert len(r_properties[\"amplitudes\"][i]) == 10, \"The list of amplitudes is not equal to 10 in patient \" + patient.filename + \" \"+ str(len(r_properties[\"amplitudes\"][i]))\n",
    "        assert r_properties[\"peaks\"][i] <=  patient.segmented_R_pos[i]+6,\"the peak position is not in range : Patient \" + patient.filename+ \" R_peak: \" + str(r_properties[\"peaks\"][i])\n",
    "        assert r_properties[\"peaks\"][i] >=  patient.segmented_R_pos[i]-6,\"the peak position is not in range : Patient \" + patient.filename+ \" R_peak: \" + str(r_properties[\"peaks\"][i])\n",
    "        assert r_properties[\"peaks\"][i] <=  r_properties[\"peaks\"][i+1], \"the later peak position is smaller: Patient \" + patient.filename+ \" R_peak: \" + str(r_properties[\"peaks\"][i]) \n",
    "        if(r_properties[\"offset\"][i] < r_properties[\"peaks\"][i]):\n",
    "            warnings.warn(\"r_peak is larger than offset. File name: \"+ patient.filename + \". r_peak: \"+ str(r_properties[\"peaks\"][i]))\n",
    "        if(r_properties[\"onset\"][i] > r_properties[\"peaks\"][i]):\n",
    "            warnings.warn(\"onset is larger than r_peak. File name: \"+ patient.filename + \". r_peak: \"+ str(r_properties[\"peaks\"][i]))\n",
    "        if(r_properties[\"onset\"][i] > r_properties[\"onset\"][i+1]):\n",
    "            warnings.warn(\"the later onset is larger than current onset. File name: \"+ patient.filename + \". r_peak: \"+ str(r_properties[\"peaks\"][i]))\n",
    "        if(r_properties[\"offset\"][i] > r_properties[\"offset\"][i+1]):\n",
    "            warnings.warn(\"the later offset is larger than current offset. File name: \"+ patient.filename + \". r_peak: \"+ str(r_properties[\"peaks\"][i]))\n",
    "        #  assert max()\n",
    "        #assert r_properties[\"onset\"][i]  <= r_properties[\"peaks\"][i],\"the peak is smaller than onset in \" + patient.filename + \" onset: \" + str(r_properties[\"onset\"][i]) +\" peak: \"+  str(r_properties[\"peaks\"][i]) \n",
    "        #assert r_properties[\"offset\"][i] >= r_properties[\"peaks\"][i],\"the peak is larger than offset in \" + patient.filename + \" offset: \" + str(r_properties[\"offset\"][i]) +\" peak: \"+  str(r_properties[\"peaks\"][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit100 = load_database.load_patient_record(\"mitdb\",\"100\")\n",
    "mit100.set_segmented_beats_r_pos(winL=100,winR=200)\n",
    "filtere_MLII = mit100.filtered_MLII\n",
    "sig = mit100.filtered_MLII[0:500]\n",
    "sig_savgol = savgol_filter(sig,41,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(numbers):\n",
    "    return float(sum(numbers)) / len(numbers)\n",
    "def peak_properties_extractor(sig,start_point=None,end_point=None,height=None, distance=None, width = None, plateau_size=None):\n",
    "    sig = sig[start_point:end_point]\n",
    "    peaks,properties  = np.asarray(signal.find_peaks(sig, height=height, distance=distance,width=width,plateau_size=plateau_size))\n",
    "    return peaks,properties\n",
    "\n",
    "def point_transform_to_origin(por,point):\n",
    "    point_from_origin = por + point \n",
    "    return point_from_origin\n",
    "\n",
    "def origin_to_new_point(por,point_from_origin):\n",
    "    point = point_from_origin - por\n",
    "    return point\n",
    "\n",
    "def peak_duration(time,right_edge, left_edge,point_from_origin):\n",
    "    right_edge = point_transform_to_origin(point_from_origin,right_edge)\n",
    "    left_edge = point_transform_to_origin(point_from_origin,left_edge)\n",
    "    \n",
    "    return float(time[right_edge]-time[left_edge])\n",
    "\n",
    "def sub_signal_interval(time, start_point, end_point,point_from_origin):\n",
    "    start_point = point_transform_to_origin(point_from_origin,start_point)\n",
    "    end_point = point_transform_to_origin(point_from_origin,end_point)\n",
    "    \n",
    "    return float(time[end_point]-time[start_point])\n",
    "\n",
    "def peak_height(signal, peak, prominence,point_from_origin):\n",
    "    peak = point_transform_to_origin(point_from_origin,peak)\n",
    "    height = signal[peak]-(signal[peak] - prominence)\n",
    "    return height\n",
    "\n",
    "def area_under_curve(signal,time,samples,point_from_origin):\n",
    "    samples = [point_transform_to_origin(i,point_from_origin) for i in samples]\n",
    "    time = np.asarray(time)\n",
    "    amplitude = np.asarray(signal)\n",
    "    area = metrics.auc(time[samples],amplitude[samples])\n",
    "    return area\n",
    "\n",
    "def amplitude(signal,samples,point_from_origin):\n",
    "    samples = [point_transform_to_origin(i,point_from_origin) for i in samples]\n",
    "    signal = np.asarray(signal)\n",
    "    amplitudes = signal[samples]\n",
    "    return amplitudes\n",
    "\n",
    "def find_Q_point(signal,time, R_peaks, time_limit = 0.01,limit=50):\n",
    "    num_peak = len(R_peaks)\n",
    "    Q_points = []   \n",
    "    for i in range(num_peak):\n",
    "        r_peak = R_peaks[i]\n",
    "        point = r_peak\n",
    "        if point-1 >= len(signal):\n",
    "            \n",
    "            break\n",
    "        \n",
    "        if(signal[point] >= 0 ):\n",
    "            while point >= R_peaks[i] - limit and signal[point] >= signal[point - 1] or abs(time[r_peak]-time[point]) <= time_limit:             \n",
    "                point -= 1\n",
    "                if point >= len(signal):\n",
    "                    break\n",
    "        else:\n",
    "            \n",
    "            while point >= R_peaks[i] - limit and abs(signal[point]) >= abs(signal[point - 1]) or abs(time[r_peak]-time[point]) <= time_limit:             \n",
    "                point -= 1\n",
    "                if point <= len(signal):\n",
    "                    break\n",
    "        \n",
    "        Q_points.append(point)\n",
    "                        \n",
    "    return np.asarray(Q_points)\n",
    "\n",
    "# only works with filtered leads \n",
    "def find_S_point(signal,time, R_peaks, time_limit = 0.01, limit=50):\n",
    "    num_peak = len(R_peaks)\n",
    "    S_points = []   \n",
    "    for i in range(num_peak):\n",
    "        \n",
    "        r_peak = R_peaks[i]\n",
    "        point = r_peak\n",
    "        if point+1 >= len(signal):\n",
    "           \n",
    "            break\n",
    "        \n",
    "        if(signal[point] >= 0 ):\n",
    "            while point <= R_peaks[i] + limit and signal[point] >= signal[point + 1] or abs(time[point]-time[r_peak]) <= time_limit:             \n",
    "                point += 1\n",
    "                if point >= len(signal):\n",
    "                   \n",
    "                    break\n",
    "        else:\n",
    "            \n",
    "            while  point <= R_peaks[i] + limit and abs(signal[point]) >= abs(signal[point + 1]) or abs(time[point]-time[r_peak]) <= time_limit:             \n",
    "                point += 1\n",
    "                if point >= len(signal):\n",
    "                    break\n",
    "        \n",
    "        S_points.append(point)\n",
    "                        \n",
    "    return np.asarray(S_points)     \n",
    "\n",
    "def q_s_peak_properties_extractor(patient,time_limit_from_r=0.1,sample_from_point=[5,5], to_area=False,to_savol=True, Order=9,window_len=41, left_limit=50,right_limit=50, distance=1, width=[0,100],plateau_size=[0,100]):\n",
    "    s_peaks = []\n",
    "    q_peaks = []\n",
    "    \n",
    "    sigs = []\n",
    "    time = patient.time\n",
    "    count = 0\n",
    "    \n",
    "    heights_q = []\n",
    "    durations_q = []\n",
    "    areas_q = []\n",
    "    onset_q = []\n",
    "    offset_q = []\n",
    "    amps_q = []\n",
    "    promi_q = []\n",
    "    \n",
    "    heights_s = []\n",
    "    durations_s = []\n",
    "    areas_s = []\n",
    "    onset_s = []\n",
    "    offset_s = []\n",
    "    amps_s = []\n",
    "    promi_s = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Patient file: \",patient.filename, \"begins\")\n",
    "    \n",
    "    if(patient.filtered_MLII == []):\n",
    "        print(\"Please filter the signal\")\n",
    "        return\n",
    "    if(patient.segmented_R_pos == []):\n",
    "        print(\"please segment the signal to find R peak\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    q_points = find_Q_point(patient.filtered_MLII,patient.time, patient.segmented_R_pos)\n",
    "    s_points = find_S_point(patient.filtered_MLII,patient.time, patient.segmented_R_pos)\n",
    "    for r in patient.segmented_R_pos:\n",
    "        start_point = r-left_limit\n",
    "        end_point = r+right_limit\n",
    "        MLII = []\n",
    "        sig = []\n",
    "        peak = None \n",
    "        properties = None\n",
    "        height = 0\n",
    "        time = patient.time[start_point:end_point] \n",
    "        if(patient.filtered_MLII[r] >= 0):\n",
    "            MLII = patient.filtered_MLII\n",
    "            sig = MLII[start_point:end_point]\n",
    "            height = min(sig)   \n",
    "        else:\n",
    "            MLII = -patient.filtered_MLII\n",
    "            sig = MLII[start_point:end_point]\n",
    "            height = min(sig)   \n",
    "        \n",
    "        if(to_savol == True):\n",
    "            sig = savgol_filter(sig,window_len,Order)\n",
    "            height = min(sig)\n",
    "            \n",
    "        peak,properties = peak_properties_extractor(sig,height=height, distance=distance, width=width, plateau_size=plateau_size)\n",
    "\n",
    "        old_sig = sig\n",
    "        old_peaks = peak\n",
    "        origin_peaks = point_transform_to_origin(start_point,peak)\n",
    "        \n",
    "        r_range_peaks = []\n",
    "\n",
    "        for p in range(0,len(old_peaks)):\n",
    "            if(origin_peaks[p] >= r-5 and origin_peaks[p] <= r+5):\n",
    "                r_range_peaks.append(old_peaks[p])\n",
    "                \n",
    "        sig = sig[r_range_peaks]\n",
    "        r_peak = 0\n",
    "        \n",
    "        if(len(sig) == 0):\n",
    "            r_peak = origin_to_new_point(start_point,r)\n",
    "\n",
    "        else: \n",
    "            value = max(sig)\n",
    "            \n",
    "            index = np.where(sig==value)\n",
    "        \n",
    "            index = int(index[0])\n",
    "    \n",
    "            r_peak = r_range_peaks[index]\n",
    "        \n",
    "        \n",
    "        peak,properties= peak_properties_extractor(-old_sig,height=height, distance=distance, width=width, plateau_size=plateau_size)\n",
    "\n",
    "        #do q points \n",
    "        q_point = 0\n",
    "        \n",
    "        previous_point = peak[0]\n",
    "        temp_point = previous_point\n",
    "        index = 0\n",
    "        for i in range(1,len(peak)):\n",
    "            \n",
    "            if peak[i] >= r_peak-5:\n",
    "                break\n",
    "            if peak[i] > previous_point:\n",
    "                \n",
    "                temp_point = peak[i]\n",
    "                previous_point = peak[i]\n",
    "                index = index + 1\n",
    "                \n",
    "        \n",
    "        if((time[origin_to_new_point(start_point,q_points[count])]-time[temp_point])<=time_limit_from_r):   \n",
    "            q_point = point_transform_to_origin(start_point,temp_point)\n",
    "            left_ips = np.asarray(properties[\"left_ips\"])\n",
    "            right_ips = np.asarray(properties[\"right_ips\"])\n",
    "            left_ips = [int(i) for i in left_ips]\n",
    "            right_ips = [int(i) for i in right_ips]\n",
    "\n",
    "        \n",
    "    \n",
    "            left_edge = left_ips[index]\n",
    "            right_edge = right_ips[index]\n",
    "        \n",
    "            duration = round(peak_duration(time=patient.time,right_edge=right_edge, left_edge=left_edge,point_from_origin=start_point),3)\n",
    "            prominences = np.asarray(properties[\"prominences\"])\n",
    "            prominence = prominences[index]\n",
    "            height = round(peak_height(-MLII, q_point, prominence,0),3)\n",
    "      \n",
    "            durations_q.append(duration)\n",
    "            promi_q.append(prominence)\n",
    "            amp = amplitude(patient.filtered_MLII,list(range(q_point-sample_from_point[0],q_point+sample_from_point[1])),0)\n",
    "        \n",
    "            heights_q.append(height)\n",
    "        \n",
    "            if(to_area==True):\n",
    "                samples = list(range(left_edge,right_edge+1))\n",
    "                area = round(area_under_curve(patient.filtered_MLII,patient.time,samples,start_point),3)\n",
    "                areas_q.append(area)\n",
    "            \n",
    "            amps_q.append(amp)\n",
    "            offset_q.append(point_transform_to_origin(right_edge+5,start_point))\n",
    "            onset_q.append(point_transform_to_origin(left_edge-5,start_point))\n",
    "        \n",
    "            q_peaks.append(q_point)\n",
    "            #print(q_point)\n",
    "        else:\n",
    "            q_point=q_points[count]\n",
    "           \n",
    "            s_peaks.append(s_point)\n",
    "            durations_s.append(0)\n",
    "            promi_s.append(0)\n",
    "            amp = amplitude(patient.filtered_MLII,list(range(s_point-sample_from_point[0],s_point+sample_from_point[1])),0)\n",
    "            heights_s.append(0)\n",
    "            if(to_area==True):\n",
    "                areas_s.append(0)\n",
    "            amps_s.append(amp)\n",
    "            offset_s.append(s_point+5)\n",
    "            onset_s.append(s_point-5)\n",
    "            #print(q_point)\n",
    " \n",
    "        #do s points\n",
    "        s_point = 0\n",
    "        temp_point = 0\n",
    "        index = i\n",
    "        \n",
    "        for i in range(0,len(peak)):\n",
    "            if peak[i] < r_peak+5:\n",
    "                continue\n",
    "            temp_point = peak[i]\n",
    "            index = i\n",
    "            break\n",
    "                        \n",
    "        if((time[temp_point]-time[origin_to_new_point(start_point,s_points[count])])<=time_limit_from_r):\n",
    "            \n",
    "            s_point = point_transform_to_origin(start_point,temp_point)\n",
    "            \n",
    "            left_ips = np.asarray(properties[\"left_ips\"])\n",
    "            right_ips = np.asarray(properties[\"right_ips\"])\n",
    "            left_ips = [int(i) for i in left_ips]\n",
    "            right_ips = [int(i) for i in right_ips]\n",
    "\n",
    "        \n",
    "    \n",
    "            left_edge = left_ips[index]\n",
    "            right_edge = right_ips[index]\n",
    "        \n",
    "            duration = round(peak_duration(time=patient.time,right_edge=right_edge, left_edge=left_edge,point_from_origin=start_point),3)\n",
    "            prominences = np.asarray(properties[\"prominences\"])\n",
    "            prominence = prominences[index]\n",
    "            height = round(peak_height(-MLII, s_point, prominence,0),3)\n",
    "      \n",
    "            durations_s.append(duration)\n",
    "            promi_s.append(prominence)\n",
    "            amp = amplitude(patient.filtered_MLII,list(range(s_point-sample_from_point[0],s_point+sample_from_point[1])),0)\n",
    "        \n",
    "            heights_s.append(height)\n",
    "        \n",
    "            if(to_area==True):\n",
    "                samples = list(range(left_edge,right_edge+1))\n",
    "                area = round(area_under_curve(patient.filtered_MLII,patient.time,samples,start_point),3)\n",
    "                areas_s.append(area)\n",
    "            \n",
    "            amps_s.append(amp)\n",
    "            offset_s.append(point_transform_to_origin(right_edge+5,start_point))\n",
    "            onset_s.append(point_transform_to_origin(left_edge-5,start_point))\n",
    "            s_peaks.append(s_point)\n",
    "                \n",
    "        else:\n",
    "            s_point=s_points[count]\n",
    "            \n",
    "            q_peaks.append(s_point)\n",
    "            durations_q.append(0)\n",
    "            promi_q.append(0)\n",
    "            amp = amplitude(patient.filtered_MLII,list(range(s_point-sample_from_point[0],s_point+sample_from_point[1])),0)\n",
    "            heights_q.append(0)\n",
    "            if(to_area==True):\n",
    "                areas_q.append(0)\n",
    "            amps_q.append(amp)\n",
    "            offset_q.append(s_point+5)\n",
    "            onset_q.append(s_point-5)\n",
    "            \n",
    "        count = count+1\n",
    "            \n",
    "                \n",
    "\n",
    "        \n",
    "    q_properties = {\n",
    "        \"peaks\" : q_peaks,\n",
    "        \"durations\" : durations_q,\n",
    "        \"prominences\" : promi_q,\n",
    "        \"height\" : heights_q,\n",
    "        \"amplitudes\" : amps_q,\n",
    "        \"areas\" : areas_q,\n",
    "        \"onset\" : onset_q,\n",
    "        \"offset\" : offset_q\n",
    "    }\n",
    "    \n",
    "    s_properties = {\n",
    "        \"peaks\" : s_peaks,\n",
    "        \"durations\" : durations_s,\n",
    "        \"prominences\" : promi_s,\n",
    "        \"height\" : heights_s,\n",
    "        \"amplitudes\" : amps_s,\n",
    "        \"areas\" : areas_s,\n",
    "        \"onset\" : onset_s,\n",
    "        \"offset\" : offset_s\n",
    "    }\n",
    "    \n",
    "        \n",
    "    return   q_peaks, q_properties , s_peaks, s_properties\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "   \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_points, q_properties,  s_points, s_properties = q_s_peak_properties_extractor(mit100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x ,y  = np.unique(q_properties[\"durations\"][0:1000], return_counts=True) # counting occurrence of each loan\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = np.asarray(q_points)\n",
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfdb.plot_items(signal=mit100.filtered_MLII, ann_samp = [ann])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qrs_durations = []\n",
    "high_qrs = []\n",
    "for i in range(0, len(mit100.segmented_R_pos)):\n",
    "    qrs_duration = round(sub_signal_interval(mit100.time, q_points[i], s_points[i],0),3)\n",
    "    \n",
    "    qrs_durations.append(qrs_duration)\n",
    "    if(qrs_duration>0.14):\n",
    "        print(mit100.segmented_R_pos[i], qrs_duration, q_points[i], s_points[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_point = 150\n",
    "end_point = 1000\n",
    "q=546775\n",
    "s=546841\n",
    "q_point = origin_to_new_point(start_point,q)\n",
    "s_point = origin_to_new_point(start_point,s)\n",
    "annotation = np.asarray([q_point,s_point])\n",
    "sig = mit100.filtered_MLII[start_point:end_point]\n",
    "sig = savgol_filter(sig,41,9)\n",
    "wfdb.plot_items(signal=sig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x ,y  = np.unique(qrs_durations, return_counts=True) # counting occurrence of each loan\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(numbers):\n",
    "    return float(sum(numbers)) / len(numbers)\n",
    "def peak_properties_extractor(sig,start_point=None,end_point=None,height=None, distance=None, width = None, plateau_size=None):\n",
    "    sig = sig[start_point:end_point]\n",
    "    peaks,properties  = np.asarray(signal.find_peaks(sig, height=height, distance=distance,width=width,plateau_size=plateau_size))\n",
    "    return peaks,properties\n",
    "\n",
    "def point_transform_to_origin(por,point):\n",
    "    point_from_origin = por + point \n",
    "    return point_from_origin\n",
    "\n",
    "def origin_to_new_point(por,point_from_origin):\n",
    "    point = point_from_origin - por\n",
    "    return point\n",
    "\n",
    "def peak_duration(time,right_edge, left_edge,point_from_origin):\n",
    "    right_edge = point_transform_to_origin(point_from_origin,right_edge)\n",
    "    left_edge = point_transform_to_origin(point_from_origin,left_edge)\n",
    "    \n",
    "    return float(time[right_edge]-time[left_edge])\n",
    "\n",
    "def sub_signal_interval(time, start_point, end_point,point_from_origin):\n",
    "    start_point = point_transform_to_origin(point_from_origin,start_point)\n",
    "    end_point = point_transform_to_origin(point_from_origin,end_point)\n",
    "    \n",
    "    return float(time[end_point]-time[start_point])\n",
    "\n",
    "def peak_height(signal, peak, prominence,point_from_origin):\n",
    "    peak = point_transform_to_origin(point_from_origin,peak)\n",
    "    height = signal[peak]-(signal[peak] - prominence)\n",
    "    return height\n",
    "\n",
    "def area_under_curve(signal,time,samples,point_from_origin):\n",
    "    samples = [point_transform_to_origin(i,point_from_origin) for i in samples]\n",
    "    time = np.asarray(time)\n",
    "    amplitude = np.asarray(signal)\n",
    "    area = metrics.auc(time[samples],amplitude[samples])\n",
    "    return area\n",
    "\n",
    "def amplitude(signal,samples,point_from_origin):\n",
    "    samples = [point_transform_to_origin(i,point_from_origin) for i in samples]\n",
    "    signal = np.asarray(signal)\n",
    "    amplitudes = signal[samples]\n",
    "    return amplitudes\n",
    "\n",
    "def find_Q_point(signal,time, R_peaks, time_limit = 0.01,limit=50):\n",
    "    num_peak = len(R_peaks)\n",
    "    Q_points = []   \n",
    "    for i in range(num_peak):\n",
    "        r_peak = R_peaks[i]\n",
    "        point = r_peak\n",
    "        if point-1 >= len(signal):\n",
    "            \n",
    "            break\n",
    "        \n",
    "        if(signal[point] >= 0 ):\n",
    "            while point >= R_peaks[i] - limit and signal[point] >= signal[point - 1] or abs(time[r_peak]-time[point]) <= time_limit:             \n",
    "                point -= 1\n",
    "                if point >= len(signal):\n",
    "                    break\n",
    "        else:\n",
    "            \n",
    "            while point >= R_peaks[i] - limit and abs(signal[point]) >= abs(signal[point - 1]) or abs(time[r_peak]-time[point]) <= time_limit:             \n",
    "                point -= 1\n",
    "                if point <= len(signal):\n",
    "                    break\n",
    "        \n",
    "        Q_points.append(point)\n",
    "                        \n",
    "    return np.asarray(Q_points)\n",
    "\n",
    "# only works with filtered leads \n",
    "def find_S_point(signal,time, R_peaks, time_limit = 0.01, limit=50):\n",
    "    num_peak = len(R_peaks)\n",
    "    S_points = []   \n",
    "    for i in range(num_peak):\n",
    "        \n",
    "        r_peak = R_peaks[i]\n",
    "        point = r_peak\n",
    "        if point+1 >= len(signal):\n",
    "           \n",
    "            break\n",
    "        \n",
    "        if(signal[point] >= 0 ):\n",
    "            while point <= R_peaks[i] + limit and signal[point] >= signal[point + 1] or abs(time[point]-time[r_peak]) <= time_limit:             \n",
    "                point += 1\n",
    "                if point >= len(signal):\n",
    "                   \n",
    "                    break\n",
    "        else:\n",
    "            \n",
    "            while  point <= R_peaks[i] + limit and abs(signal[point]) >= abs(signal[point + 1]) or abs(time[point]-time[r_peak]) <= time_limit:             \n",
    "                point += 1\n",
    "                if point >= len(signal):\n",
    "                    break\n",
    "        \n",
    "        S_points.append(point)\n",
    "                        \n",
    "    return np.asarray(S_points)     \n",
    "\n",
    "def p_and_t_peak_properties_extractor(patient,time_limit_from_r=0.1,sample_from_point=[5,5], to_area=False,to_savol=False, Order=9,window_len=31, left_limit=50,right_limit=50, distance=1, width=[0,100],plateau_size=[0,100]):\n",
    "    p_peaks = []\n",
    "    p_heights = []\n",
    "    p_durations = []\n",
    "    p_areas = []\n",
    "    p_onset = []\n",
    "    p_offset = []\n",
    "    p_amps = []\n",
    "    p_promi = []\n",
    "    sigs = []\n",
    "    \n",
    "    t_peaks = []\n",
    "    t_heights = []\n",
    "    t_durations = []\n",
    "    t_areas = []\n",
    "    t_onset = []\n",
    "    t_offset = []\n",
    "    t_amps = []\n",
    "    t_promi = []\n",
    "    \n",
    "    p_positives = []\n",
    "    p_negatives = []\n",
    "    t_positives = []\n",
    "    t_negatives = []\n",
    "    \n",
    "    \n",
    "    time = patient.time\n",
    "    count = 0\n",
    "    print(\"Patient file: \",patient.filename, \"begins\")\n",
    "    \n",
    "    if(patient.filtered_MLII == []):\n",
    "        print(\"Please filter the signal\")\n",
    "        return\n",
    "    if(patient.segmented_R_pos == []):\n",
    "        print(\"please segment the signal to find R peak\")\n",
    "        return\n",
    "    \n",
    "    if(patient.Q_points == []): \n",
    "        print(\"please segment the signal to find Q peak\")\n",
    "        return\n",
    "    \n",
    "    if(patient.S_points == []):\n",
    "        print(\"please segment the signal to find S peak\")\n",
    "        return\n",
    "    \n",
    "\n",
    "    r_peaks = patient.segmented_R_pos\n",
    "    q_peaks = patient.Q_points\n",
    "    s_peaks = patient.S_points\n",
    "    #q_peaks = patient.Q_points_properites[\"peaks\"]\n",
    "    #s_peaks = patient.S_points_properites[\"peaks\"]\n",
    "        \n",
    "    first_r_sig = patient.filtered_MLII[q_peaks[0]-100:q_peaks[0]]\n",
    "    last_r_sig = patient.filtered_MLII[s_peaks[len(s_peaks)-1]:s_peaks[len(s_peaks)-1]+100]\n",
    "    \n",
    "    pre_r_sig = first_r_sig\n",
    "    start_pre_r = q_peaks[0]-100\n",
    "    post_r_sig = patient.filtered_MLII[s_peaks[0]:r_peaks[1]]\n",
    "    start_post_r = s_peaks[0]\n",
    "    \n",
    "    for i in range(0,len(r_peaks)):\n",
    "        ####pre_processing\n",
    "        \n",
    "        negative_pre = -pre_r_sig\n",
    "        \n",
    "        if(to_savol == True):\n",
    "            pre_r_sig = savgol_filter(pre_r_sig,window_len,Order)\n",
    "            negative_pre = savgol_filter(negative_pre,window_len,Order)\n",
    "\n",
    "        peak,properties= peak_properties_extractor(pre_r_sig, distance=distance, width=width, plateau_size=plateau_size)\n",
    "        neg_peak,neg_properties= peak_properties_extractor(negative_pre, distance=distance, width=width, plateau_size=plateau_size)\n",
    "        ########\n",
    "        #######do operation to find the p wave\n",
    "        \n",
    "        abs_peak = [point_transform_to_origin(p, start_pre_r) for p in peak]\n",
    "        abs_neg_peak = [point_transform_to_origin(p, start_pre_r) for p in neg_peak]\n",
    "    \n",
    "        left, right = sudo_k_mean(abs_peak, time)\n",
    "        neg_left, neg_right = sudo_k_mean(abs_neg_peak, time)\n",
    "        \n",
    "        p_pos = highest_peak(right, patient.filtered_MLII)\n",
    "        p_neg = highest_peak(neg_right,-patient.filtered_MLII)\n",
    "        \n",
    "        \n",
    "        ######Turn to normal peak to find the other properties\n",
    "        \n",
    "        \n",
    "        p_positives.append(p_pos)\n",
    "        index_pos = find_index(abs_peak, p_pos)\n",
    "        p_peak = peak[index_pos]\n",
    "        point, duration, prominence, height, amp, area, offset, onset=find_values_in_properties(patient,patient.filtered_MLII ,p_peak, properties, index_pos, sample_from_point, start_point,to_area)\n",
    "        p_negatives.append(p_neg)\n",
    "        index_neg = find_index(abs_neg_peak, p_neg)\n",
    "        p_neg_peak = peak[index_neg]\n",
    "        point_neg, duration_neg, prominence_neg, height_neg, amp_neg, area_neg, offset_neg, onset_neg=find_values_in_properties(patient,-patient.filtered_MLII ,p_neg_peak, neg_properties, index_neg, sample_from_point, start_point,to_area)\n",
    "\n",
    "        p_peaks.append((p_positives,p_negatives))\n",
    "        p_heights.append((height,height_neg))\n",
    "        p_durations.append((duration,duration_neg))\n",
    "        p_areas.append((area,area_neg))\n",
    "        p_onset.append((onset,onset_neg))\n",
    "        p_offset.append((offset,offset_neg))\n",
    "        p_amps.append((amp, amp_neg))\n",
    "        p_promi.append((prominence,prominence_neg))\n",
    "        \n",
    "        ##################################################\n",
    "        negative_post = -post_r_sig\n",
    "        \n",
    "        if(to_savol == True):\n",
    "            post_r_sig = savgol_filter(post_r_sig,window_len,Order)\n",
    "            negative_post = savgol_filter(negative_post,window_len,Order)\n",
    "\n",
    "        peak,properties= peak_properties_extractor(post_r_sig, distance=distance, width=width, plateau_size=plateau_size)\n",
    "        neg_peak,neg_properties= peak_properties_extractor(negative_post, distance=distance, width=width, plateau_size=plateau_size)\n",
    "        \n",
    "        ########\n",
    "        #######do operation to find the t wave\n",
    "        abs_peak = [point_transform_to_origin(p, start_post_r) for p in peak]\n",
    "        abs_neg_peak = [point_transform_to_origin(p, start_post_r) for p in neg_peak]\n",
    "        #print(len(abs_peak))\n",
    "        left, right = sudo_k_mean(abs_peak, time)\n",
    "        neg_left, neg_right = sudo_k_mean(abs_neg_peak, time)\n",
    "        \n",
    "        t_pos = highest_peak(left, patient.filtered_MLII)\n",
    "        t_neg = highest_peak(neg_left,-patient.filtered_MLII)\n",
    "        \n",
    "        t_positives.append(t_pos)\n",
    "        index_pos = find_index(abs_peak, t_pos)\n",
    "        t_peak = peak[index_pos]\n",
    "        point, duration, prominence, height, amp, area, offset, onset=find_values_in_properties(patient,patient.filtered_MLII ,t_peak, properties, index_pos, sample_from_point, start_point,to_area)\n",
    "        t_negatives.append(t_neg)\n",
    "        index_neg = find_index(abs_neg_peak, t_neg)\n",
    "        t_neg_peak = peak[index_neg]\n",
    "        point_neg, duration_neg, prominence_neg, height_neg, amp_neg, area_neg, offset_neg, onset_neg=find_values_in_properties(patient,-patient.filtered_MLII ,t_neg_peak, neg_properties, index_neg, sample_from_point, start_point,to_area)\n",
    "\n",
    "        t_peaks.append((t_positives,t_negatives))\n",
    "        t_heights.append((height,height_neg))\n",
    "        t_durations.append((duration,duration_neg))\n",
    "        t_areas.append((area,area_neg))\n",
    "        t_onset.append((onset,onset_neg))\n",
    "        t_offset.append((offset,offset_neg))\n",
    "        t_amps.append((amp, amp_neg))\n",
    "        t_promi.append((prominence,prominence_neg))\n",
    "        \n",
    "        ########next wave _________________________________________\n",
    "        \n",
    "        if(i == len(r_peaks)-1):\n",
    "            break\n",
    "           \n",
    "        pre_r_sig = patient.filtered_MLII[s_peaks[i]:q_peaks[i+1]]\n",
    "        if(i==0):\n",
    "            print(s_peaks[i], q_peaks[i+1])\n",
    "       # print(\"before next \",patient.filtered_MLII[s_peaks[i]:q_peaks[i-1]])\n",
    "        start_pre_r = s_peaks[i]\n",
    "        if(i == len(r_peaks)-2):\n",
    "            post_r_sig = last_r_sig\n",
    "            start_post_r = s_peaks[len(s_peaks)-1]\n",
    "            \n",
    "        else:\n",
    "            post_r_sig = patient.filtered_MLII[s_peaks[i+1]:q_peaks[i+2]]\n",
    "            start_post_r = s_peaks[i+1]\n",
    "            \n",
    "    \n",
    "    p_properties = {\n",
    "        \"peaks\" : p_peaks,\n",
    "        \"durations\" : p_durations,\n",
    "        \"prominences\" : p_promi,\n",
    "        \"height\" : p_heights,\n",
    "        \"amplitudes\" : p_amps,\n",
    "        \"areas\" : p_areas,\n",
    "        \"onset\" : p_onset,\n",
    "        \"offset\" : p_offset\n",
    "    }\n",
    "    \n",
    "    t_properties = {\n",
    "        \"peaks\" : t_peaks,\n",
    "        \"durations\" : t_durations,\n",
    "        \"prominences\" : t_promi,\n",
    "        \"height\" : t_heights,\n",
    "        \"amplitudes\" : t_amps,\n",
    "        \"areas\" : t_areas,\n",
    "        \"onset\" : t_onset,\n",
    "        \"offset\" : t_offset\n",
    "    }\n",
    "        \n",
    "    return p_positives, p_negatives, p_properties, t_positives, t_negatives, t_properties\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(ls,value):\n",
    "    index = np.where(ls==value)\n",
    "        \n",
    "    index = int(index[0])\n",
    "    \n",
    "    return index\n",
    "\n",
    "def find_values_in_properties(patient,signal ,peak, properties, index, sample_from_point, start_point,to_area):\n",
    "\n",
    "    point = point_transform_to_origin(peak,start_point)\n",
    "            \n",
    "    left_ips = np.asarray(properties[\"left_ips\"])\n",
    "    right_ips = np.asarray(properties[\"right_ips\"])\n",
    "    left_ips = [int(i) for i in left_ips]\n",
    "    right_ips = [int(i) for i in right_ips]\n",
    "\n",
    "        \n",
    "    \n",
    "    left_edge = left_ips[index]\n",
    "    right_edge = right_ips[index]\n",
    "        \n",
    "    duration = round(peak_duration(time=patient.time,right_edge=right_edge, left_edge=left_edge,point_from_origin=start_point),3)\n",
    "    prominences = np.asarray(properties[\"prominences\"])\n",
    "    prominence = prominences[index]\n",
    "    height = round(peak_height(signal, point, prominence,0),3)\n",
    "      \n",
    "    \n",
    "    amp = amplitude(patient.filtered_MLII,list(range(point-sample_from_point[0],point+sample_from_point[1])),0)\n",
    "        \n",
    "    area = None\n",
    "        \n",
    "    if(to_area==True):\n",
    "        samples = list(range(left_edge,right_edge+1))\n",
    "        area = round(area_under_curve(patient.filtered_MLII,patient.time,samples,start_point),3)\n",
    "\n",
    "            \n",
    "    \n",
    "    offset = point_transform_to_origin(right_edge+5,start_point)\n",
    "    onset = point_transform_to_origin(left_edge-5,start_point)\n",
    "    \n",
    "    return point, duration, prominence, height, amp, area, offset, onset\n",
    "  \n",
    "    \n",
    "def sudo_k_mean(ls, time):\n",
    "    first_element = ls[0]\n",
    "    last_element = ls[len(ls)-1]\n",
    "    \n",
    "    left = []\n",
    "    right = []\n",
    "    \n",
    " \n",
    "    left.append(first_element)\n",
    "    right.append(last_element)\n",
    "    for l in range(1, len(ls)-1):\n",
    "        time_1 = [time[i] for i in left]\n",
    "        time_2 = [time[i] for i in right]\n",
    "    \n",
    "        \n",
    "        centroid_1 = average(time_1)\n",
    "       # print(centroid_1, \"centroid_1\")\n",
    "        centroid_2 = average(time_2)\n",
    "       # print(centroid_2, \"centroid_2\")\n",
    "       \n",
    "        point = ls[l]\n",
    "        time_point = time[point]\n",
    "       # print(point, \"point\")\n",
    "       # print(\"time\", time_point)\n",
    "        \n",
    "        diff_1 = abs(time_point-centroid_1)\n",
    "        diff_2 = abs(time_point-centroid_2)\n",
    "        \n",
    "        if(diff_1 > diff_2):\n",
    "            right.append(point)\n",
    "        else:\n",
    "            left.append(point)\n",
    "        \n",
    "    return left, right \n",
    "        \n",
    "        \n",
    "def highest_peak(peaks, signal):\n",
    "    signal = signal[peaks]\n",
    "    max_signal = max(signal)\n",
    "    index = np.where(signal==max_signal)\n",
    "        \n",
    "    index = int(index[0])\n",
    "    \n",
    "    highest = peaks[index]\n",
    "    \n",
    "    return highest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit100.set_Q_S_points_MLII()\n",
    "p_positives, p_negatives, p_properties, t_positives, t_negatives, t_properties = p_and_t_peak_properties_extractor(mit100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(mit100.segmented_R_pos)-1):\n",
    "    point_list = list(range(mit100.segmented_R_pos[i-1],mit100.segmented_R_pos[i]))\n",
    "    assert p_positives[i] in point_list\n",
    "    assert (p_positives[i+1] in point_list) == False\n",
    "    assert (p_positives[i-1] in point_list) == False\n",
    "    assert mit100.segmented_R_pos[i] > p_positives[i]\n",
    "    assert p_positives[i] < p_positives[i+1]\n",
    "    assert mit100.segmented_R_pos[i-1] < p_positives[i], str(mit100.segmented_R_pos[i-1]) + \" \" +  str(p_positives[i])\n",
    "    \n",
    "    \n",
    "    point_list_2 = list(range(mit100.segmented_R_pos[i],mit100.segmented_R_pos[i+1]))\n",
    "    assert t_positives[i] in point_list_2\n",
    "    assert (t_positives[i+1] in point_list) == False\n",
    "    assert (t_positives[i-1] in point_list_2) == False\n",
    "    assert t_positives[i] < t_positives[i+1]\n",
    "    assert mit100.segmented_R_pos[i] < t_positives[i]\n",
    "    assert mit100.segmented_R_pos[i+1] > t_positives[i], str(mit100.segmented_R_pos[i-1]) + \" \" +  str(t_positives[i])\n",
    "    #peak,properties= peak_properties_extractor(mit100.filtered_MLII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfdb.plot_items(signal=sig, ann_samp=[peak])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
